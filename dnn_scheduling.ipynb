{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ueJ6BltCulU0"
   },
   "source": [
    "# DNN-based TSCH scheduling\n",
    "\n",
    "Notebook to retrieve a dataset of inputs and outputs of a scheduling algorithm, train a DNN model and test its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F9-E_tdzu6gQ"
   },
   "source": [
    "## 0. Import PyTorch and setup device agnostic code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "aIg02HMxvXem",
    "outputId": "209acda4-a9a8-4ee3-efd0-348cebb1a276"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "I1j50SpzvdWN",
    "outputId": "10f654b5-425c-4b23-f17f-c849b7546386"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6lrBMY4-vqi0",
    "outputId": "ca7b69c1-a185-4897-f655-f39f79aae2b5"
   },
   "outputs": [],
   "source": [
    "# see available gpu (if available)\n",
    "if device==\"cuda\":\n",
    "  !nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yiymYD_Rv0Tb"
   },
   "source": [
    "## 1. Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iw0wWjANCjf4",
    "outputId": "f91b298d-b79b-4862-e066-44cf6c08180b"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "WVh6O7PaSE0N"
   },
   "outputs": [],
   "source": [
    "# Define the TASADataset class\n",
    "\n",
    "class TASADataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        self.hdf5_file = h5py.File(self.file_path, 'r')\n",
    "        self.inputs = self.hdf5_file['inputs']\n",
    "        self.outputs = self.hdf5_file['outputs']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_data = torch.tensor(self.inputs[idx], dtype=torch.float32)\n",
    "        output_data = torch.tensor(self.outputs[idx], dtype=torch.float32)\n",
    "\n",
    "        return input_data, output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wpRebCIPwd7U",
    "outputId": "cb354c2d-bc34-4c26-db25-8e105b165790"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating DataLoader's with batch size 32\n",
      "torch.Size([32, 12])\n",
      "torch.Size([32, 420])\n",
      "\n",
      "DataLoaders created!!!!!!!\n"
     ]
    }
   ],
   "source": [
    " # Define the file path to the HDF5 database\n",
    "hdf5_file_path = 'database.h5'\n",
    "\n",
    "# Create a TASADataset instance\n",
    "tasa_dataset = TASADataset(hdf5_file_path)\n",
    "\n",
    "# Define the train and test sizes\n",
    "train_size = 0.8  # 80% for training, adjust as needed\n",
    "test_size = 1 - train_size\n",
    "\n",
    "# Split the dataset into train and test subsets\n",
    "train_indices, test_indices = train_test_split(range(len(tasa_dataset)), test_size=test_size, random_state=42)\n",
    "\n",
    "# Create train and test datasets using Subset\n",
    "train_dataset = Subset(tasa_dataset, train_indices)\n",
    "test_dataset = Subset(tasa_dataset, test_indices)\n",
    "\n",
    "# Create a DataLoader for batching and shuffling\n",
    "batch_size = 32\n",
    "print(f\"Creating DataLoader's with batch size {batch_size}\")\n",
    "shuffle = True\n",
    "\n",
    "# Create train and test data loaders\n",
    "train_dataloader = DataLoader(train_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=shuffle)\n",
    "test_dataloader = DataLoader(test_dataset,\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle = False)\n",
    "\n",
    "# Example usage:\n",
    "for inputs, outputs in train_dataloader:\n",
    "    # Send batches to the device\n",
    "    inputs = inputs.to(device)\n",
    "    outputs = outputs.to(device)\n",
    "    print(inputs.shape)\n",
    "    print(outputs.shape)\n",
    "    break\n",
    "\n",
    "print(\"\\nDataLoaders created!!!!!!!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WWjtFM9t02de",
    "outputId": "0580be56-8da1-40da-b157-625a3e383bb1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 420)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store input and ouput lengths\n",
    "for inputs, outputs in train_dataloader:\n",
    "  input_len = inputs.shape[1]\n",
    "  output_len = outputs.shape[1]\n",
    "  break\n",
    "\n",
    "input_len, output_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zNMj60_y4XLO"
   },
   "source": [
    "## 2. DNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12TcX8BH4vVJ"
   },
   "source": [
    "### 2.1 Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7BQJmxVs55dr",
    "outputId": "196a775e-5bfa-4f68-fdb1-299f40353909"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNN_Scheduler(\n",
       "  (linear_layer_stack): Sequential(\n",
       "    (0): Linear(in_features=12, out_features=800, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=800, out_features=1024, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=1024, out_features=800, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=800, out_features=420, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DNN_Scheduler(nn.Module):\n",
    "    \"\"\"\n",
    "    model architecture for a DNN-based TSCH Scheduler\n",
    "    using simple MLP architecture with non-linear activations\n",
    "    \"\"\"\n",
    "    def __init__(self, input_features: int, output_features: int, hidden_units: int = 8) -> None:\n",
    "        \"\"\"initializes all required hyperparameters\n",
    "\n",
    "        Args:\n",
    "            input_features (int): number of input features to the model\n",
    "            out_features (int): number of output features of the model\n",
    "            hidden_units (int): number of hidden units between layers, default 8\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.linear_layer_stack = nn.Sequential(\n",
    "            nn.Linear(in_features=input_features, out_features=400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=400, out_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=512, out_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=512, out_features=450),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=450, out_features=output_features),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "      return self.linear_layer_stack(x)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model_0 = DNN_Scheduler(input_features=input_len, # number of links to schedule\n",
    "                  hidden_units=50,\n",
    "                  output_features=output_len).to(device) #number of cells in schedule (4 channel offsets, 5 timeslots)\n",
    "model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IRo-sx0I1sQE",
    "outputId": "42d26b19-29ad-41b5-9702-1942f88b584a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output logits:\n",
      "tensor([ 0.0715,  0.0286,  0.1109,  0.0179, -0.0207, -0.0523,  0.0233, -0.0607,\n",
      "        -0.0076, -0.0325, -0.0674, -0.0293,  0.0601,  0.0052, -0.0437, -0.0190,\n",
      "         0.0637, -0.0220, -0.0080, -0.0098,  0.0640,  0.0261,  0.0161,  0.0004,\n",
      "         0.0585, -0.0417,  0.0114,  0.0503, -0.0140, -0.0415,  0.0403, -0.0372,\n",
      "         0.0143, -0.0334, -0.0509, -0.0121, -0.0327,  0.0046,  0.1009, -0.0676,\n",
      "        -0.0100, -0.0238, -0.0999, -0.0515,  0.0792,  0.0748,  0.0309, -0.0238,\n",
      "         0.0194, -0.1153,  0.0211, -0.0752,  0.0834, -0.0677, -0.0557,  0.0029,\n",
      "        -0.0460, -0.0626, -0.0454,  0.0190, -0.0239, -0.0394,  0.0149, -0.0420,\n",
      "        -0.0032, -0.0817,  0.0109, -0.0286, -0.0299,  0.0944, -0.1000,  0.0276,\n",
      "         0.0070, -0.0020, -0.0388,  0.0502,  0.0288,  0.0119,  0.0349,  0.0336,\n",
      "         0.0267, -0.0364,  0.0010, -0.0452, -0.0749,  0.0109,  0.0218, -0.0080,\n",
      "         0.0389, -0.0272, -0.0994,  0.0002, -0.0299,  0.0504,  0.0473, -0.0140,\n",
      "        -0.0455,  0.1103,  0.0907,  0.0207, -0.0127,  0.0780,  0.0075,  0.0350,\n",
      "        -0.0131, -0.0165, -0.0938,  0.0406, -0.0887,  0.0301,  0.0317, -0.0185,\n",
      "         0.0214, -0.0114, -0.0288, -0.0045,  0.0636, -0.0246, -0.0723,  0.0036,\n",
      "        -0.0109,  0.0784,  0.0216,  0.0206,  0.0231, -0.0250,  0.0173, -0.0169,\n",
      "         0.0609, -0.0647, -0.0062,  0.0337, -0.1257, -0.0449, -0.0006, -0.0016,\n",
      "         0.0327,  0.0401, -0.0244,  0.0025,  0.0403, -0.0081,  0.0271,  0.0102,\n",
      "         0.0319, -0.0014, -0.0043,  0.0963, -0.0456,  0.0066, -0.0736, -0.0715,\n",
      "         0.0091, -0.0232, -0.0053,  0.0839, -0.0273, -0.0376,  0.0408, -0.0390,\n",
      "         0.0252,  0.0161,  0.0253,  0.0053,  0.0075,  0.0688,  0.0992,  0.0521,\n",
      "        -0.0670, -0.0112,  0.0226,  0.0279,  0.0032,  0.0107, -0.0088,  0.0367,\n",
      "         0.0038,  0.0722,  0.0858,  0.0302, -0.0730, -0.0434,  0.0517, -0.0842,\n",
      "         0.0307,  0.0747, -0.0079,  0.0010,  0.0161,  0.0292, -0.0482,  0.0650,\n",
      "         0.0552,  0.0548,  0.0206,  0.0567, -0.0324, -0.0956, -0.0684, -0.0260,\n",
      "        -0.0123,  0.0208,  0.0645,  0.0357, -0.0827, -0.0409, -0.0398, -0.0627,\n",
      "         0.0453, -0.0149,  0.0312, -0.0551,  0.0116, -0.0876, -0.0286,  0.0832,\n",
      "        -0.0010,  0.0700,  0.1516,  0.0175,  0.1237,  0.0267,  0.0142,  0.0091,\n",
      "         0.0712, -0.0090, -0.0152,  0.0806, -0.0501,  0.0205,  0.0289,  0.0335,\n",
      "         0.0097, -0.0930,  0.0793, -0.0225, -0.0268, -0.0490, -0.0619, -0.0417,\n",
      "        -0.0276, -0.0102, -0.0229,  0.0221,  0.0313,  0.0094, -0.0086, -0.0028,\n",
      "        -0.0292, -0.0637, -0.0852,  0.0351,  0.0066, -0.0239, -0.0120, -0.0371,\n",
      "         0.0594, -0.0352, -0.0307, -0.0971, -0.0163, -0.0984, -0.0547, -0.0178,\n",
      "        -0.0297, -0.0210,  0.0867,  0.0351,  0.0658,  0.0070,  0.0582, -0.0216,\n",
      "         0.0227,  0.0877,  0.0207,  0.0126, -0.0779,  0.0181, -0.0326, -0.0244,\n",
      "         0.0185,  0.0381,  0.0388, -0.0530,  0.0171, -0.0272,  0.0187,  0.0492,\n",
      "         0.0212, -0.0442, -0.0557,  0.0189,  0.0455, -0.0062, -0.0475, -0.0420,\n",
      "         0.0046, -0.0083, -0.0297,  0.0638, -0.0211,  0.0792,  0.0672,  0.0334,\n",
      "         0.0134, -0.0220, -0.0557, -0.0152, -0.0516, -0.0246,  0.0344,  0.0244,\n",
      "        -0.0396, -0.0318, -0.0152,  0.0208,  0.0366, -0.0168,  0.0509, -0.1020,\n",
      "        -0.0202,  0.0808,  0.0417, -0.0654,  0.0410,  0.0622,  0.0682, -0.0451,\n",
      "         0.0121,  0.0183,  0.0647, -0.0276,  0.0219,  0.0745,  0.0774, -0.0010,\n",
      "        -0.0533,  0.0270,  0.0281,  0.0605,  0.0713,  0.0583, -0.0218,  0.0025,\n",
      "         0.0011,  0.0098,  0.0055, -0.0195,  0.0213,  0.0798, -0.1020,  0.0267,\n",
      "        -0.0288, -0.0418, -0.0765, -0.0046, -0.0053, -0.0398, -0.0071, -0.0321,\n",
      "        -0.0028, -0.0682,  0.0053, -0.0071, -0.0121, -0.0559, -0.0012, -0.0905,\n",
      "         0.0519, -0.0374,  0.0038, -0.0365, -0.0120,  0.0443,  0.0906,  0.0080,\n",
      "        -0.0556, -0.0388, -0.0670, -0.0128,  0.0601, -0.0179,  0.0432, -0.0543,\n",
      "        -0.0395,  0.0036, -0.0318, -0.0612,  0.0048,  0.0329,  0.0212,  0.0116,\n",
      "         0.0151,  0.0093,  0.0560,  0.0955, -0.0022,  0.0002, -0.0403,  0.0807,\n",
      "        -0.0162, -0.0109,  0.1158, -0.0115, -0.0198, -0.0134, -0.0906, -0.0215,\n",
      "         0.0993, -0.0183, -0.0254,  0.0444, -0.0098, -0.0471,  0.0377, -0.0324,\n",
      "         0.0069,  0.0158,  0.0384, -0.0527])\n",
      "\n",
      "Rounded outputs:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "Actual output:\n",
      "tensor([ 0., 12., 12., 12., 11.,  5.,  8.,  5.,  6.,  3.,  9.,  3.,  8.,  3.,\n",
      "         9.,  3.,  8.,  9.,  3.,  8.,  9.,  2.,  3.,  4.,  1.,  2.,  3.,  4.,\n",
      "         1.,  2.,  3.,  4.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  7.,  7.,  7.,  8.,  3.,  1.,  3.,  8.,  0.,  1.,  0.,  2.,  0.,\n",
      "         4.,  0.,  1.,  2.,  0.,  4.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0., 10., 10., 10.,  1.,  0.,  0.,  0.,  4.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  5.,  3.,  6.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  3.,  0.,  3.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# try a forward pass to test the model\n",
    "\n",
    "# get a batch\n",
    "input_batch, output_batch = next(iter(train_dataloader))\n",
    "\n",
    "# get a single sample from batch\n",
    "input, output = input_batch[0], output_batch[0]\n",
    "\n",
    "# do a forward pass on a single sample\n",
    "model_0.eval()\n",
    "with torch.inference_mode():\n",
    "  pred = model_0(input.to(device))\n",
    "\n",
    "# print out what is happening\n",
    "print(f\"Output logits:\\n{pred}\\n\")\n",
    "print(f\"Rounded outputs:\\n{torch.round(torch.clamp_min(pred, min=0))}\\n\")\n",
    "print(f\"Actual output:\\n{output}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HeAqzvuY8Uwr"
   },
   "source": [
    "## 2.2 Creating a loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "qZc_oeUT8ib5"
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "# loss_fn = nn.L1Loss()\n",
    "#optimizer = torch.optim.SGD(model_0.parameters(),\n",
    "                            #lr = 0.01)\n",
    "optimizer = torch.optim.Adam(model_0.parameters(),\n",
    "                             lr = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vtg5Qmmu-cF6"
   },
   "source": [
    "### 2.3 Get model info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ntai-vZ2-iCN",
    "outputId": "071a90b4-82ae-4f07-b2f1-16c7387a14e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "DNN_Scheduler                            [420]                     --\n",
       "├─Sequential: 1-1                        [420]                     --\n",
       "│    └─Linear: 2-1                       [800]                     10,400\n",
       "│    └─ReLU: 2-2                         [800]                     --\n",
       "│    └─Linear: 2-3                       [1024]                    820,224\n",
       "│    └─ReLU: 2-4                         [1024]                    --\n",
       "│    └─Linear: 2-5                       [1024]                    1,049,600\n",
       "│    └─ReLU: 2-6                         [1024]                    --\n",
       "│    └─Linear: 2-7                       [800]                     820,000\n",
       "│    └─ReLU: 2-8                         [800]                     --\n",
       "│    └─Linear: 2-9                       [420]                     336,420\n",
       "==========================================================================================\n",
       "Total params: 3,036,644\n",
       "Trainable params: 3,036,644\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 2.72\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.03\n",
       "Params size (MB): 12.15\n",
       "Estimated Total Size (MB): 12.18\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    import torchinfo\n",
    "except:\n",
    "    !pip install torchinfo\n",
    "    import torchinfo\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "summary(model_0, input_size=[input_len]) # do a test pass through of an example input size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8oMM7Qe1-rsR"
   },
   "source": [
    "### 5.6 Create train and test loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "y8Orhp2P_Vl6"
   },
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               dataloader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer):\n",
    "    # put model in train mode\n",
    "    model.train()\n",
    "\n",
    "    # setup train loss and train accuracy values\n",
    "    train_loss, train_acc = 0, 0\n",
    "\n",
    "    # Create a tqdm progress bar for the data loader\n",
    "    dataloader_iter = tqdm(enumerate(dataloader), desc=\"Training\", total=len(dataloader))\n",
    "\n",
    "    # loop through data loader data batches\n",
    "    for batch, (X, y) in dataloader_iter:\n",
    "        # send data to target device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # 1. forward pass\n",
    "        y_pred = model(X)\n",
    "\n",
    "        # 2. calculate  and accumulate loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # 3. optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        # calculate and accumulate accuracy metric across all batches\n",
    "        y_pred_round = torch.round(torch.clamp_min(y_pred, min=0))\n",
    "        train_acc += ((y_pred_round == y).sum(dim=1)/y_pred_round.shape[1]).mean().item()\n",
    "\n",
    "        # Update tqdm progress bar description\n",
    "        dataloader_iter.set_postfix({'loss': loss.item(), 'accuracy': ((y_pred_round == y).sum(dim=1)/y_pred_round.shape[1]).mean().item()})\n",
    "\n",
    "    # adjust metrics to get average loss and accuracy per batch\n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    train_acc = train_acc / len(dataloader)\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "4aqXmxep_zpJ"
   },
   "outputs": [],
   "source": [
    "def test_step(model: torch.nn.Module,\n",
    "              dataloader: torch.utils.data.DataLoader,\n",
    "              loss_fn: torch.nn.Module):\n",
    "    # put model in eval mode\n",
    "    model.eval()\n",
    "\n",
    "    # setup test loss and test accuracy values\n",
    "    test_loss, test_acc = 0, 0\n",
    "\n",
    "    # turn on inference context manager\n",
    "    with torch.inference_mode():\n",
    "        # loop through DataLoader batches\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            # send data to target device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # 1. forward pass\n",
    "            test_pred = model(X)\n",
    "\n",
    "            # 2. calculate and accumulate loss\n",
    "            loss = loss_fn(test_pred, y)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # calculate and accumulate accuracy\n",
    "            test_pred_round = torch.round(torch.clamp_min(test_pred, min=0))\n",
    "            test_acc += ((test_pred_round == y).sum(dim=1)/test_pred_round.shape[1]).mean().item()\n",
    "\n",
    "\n",
    "    # Adjust metrics to get average loss and accuracy per batch\n",
    "    test_loss = test_loss / len(dataloader)\n",
    "    test_acc = test_acc / len(dataloader)\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "L-O9gNrOAepz"
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "# 1. take in various parameters required for training and test steps\n",
    "def train(model: torch.nn.Module,\n",
    "          train_dataloader: torch.utils.data.DataLoader,\n",
    "          test_dataloader: torch.utils.data.DataLoader,\n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          epochs: int = 5):\n",
    "\n",
    "    # 2. create empty results dictionary\n",
    "    results = {\"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"test_loss\": [],\n",
    "        \"test_acc\": []\n",
    "    }\n",
    "\n",
    "    # 3. loop through training and testing steps for a number of epochs\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                           dataloader=train_dataloader,\n",
    "                                           loss_fn=loss_fn,\n",
    "                                           optimizer=optimizer)\n",
    "        test_loss, test_acc = test_step(model=model,\n",
    "                                        dataloader=test_dataloader,\n",
    "                                        loss_fn=loss_fn)\n",
    "\n",
    "        # 4. print out what's happening\n",
    "        print(\n",
    "            f\"Epoch: {epoch+1} | \"\n",
    "            f\"train_loss: {train_loss:.4f} | \"\n",
    "            f\"train_acc: {train_acc:.4f} | \"\n",
    "            f\"test_loss: {test_loss:.4f} | \"\n",
    "            f\"test_acc: {test_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        # 5. update results dictionary\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "    # 6. return the filled results at the end of the epochs\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uas6aoGSA3tY",
    "outputId": "6f8abc33-e586-4f68-c1cb-a8f371af75ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0_OlshxQA_mp"
   },
   "source": [
    "### 5.7 Train and evaluate DNN scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 862,
     "referenced_widgets": [
      "d23fb7552f7042648c934374c8ed6b9a",
      "1208b62ba06e4009a7e07cf4d6e0df3f",
      "bfdbd85bb84844fb8b4f39cce3cd7fb1",
      "c16517ff94954b74a9d9e683c89584aa",
      "cbe6efd79de14fec8b3f6d1de6a88f66",
      "48294fc2a3e64382a3a5af7a37b69317",
      "61384ea5ec6a47b9aebe1ae3f981b206",
      "b0d7f26663d74cc9877924a1cfd337d3",
      "43c5458339d149f9accef7a6bf96c112",
      "48f38e504c9943d2ada8432fba672a5c",
      "063479aeceae458e8382e5270c1368a1",
      "5cc6ced4a8884baf83e0f513a8320717",
      "3fc1b5eba23d4fec824f4204270ab7df",
      "0e751d8cfa9b4b018f53154e79912c3b",
      "c45e2aeb0f4049278b48877b7c7e4feb",
      "11943b53b4724193a73924d3d692488e",
      "7a932c7673be4f8d8e1c262c7f1045d9",
      "443270b905554c14af2da66c14ca332a",
      "42cbdbf178424a859cf8b017904ffb65",
      "d1e39dac365c4909b35a5cbbf99578cd",
      "aa1114ba88924695923a00706f2ddf67",
      "3fb22ccf76bf4c0d83acc0c1c04987b8"
     ]
    },
    "id": "01yLEVOkBHhz",
    "outputId": "7f4796f2-45ea-4e95-c947-e58b6629613f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "003bf6e1d04446f58689f931b309ec6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e38b8a0748e849c68b2554603cba946c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 0.1833 | train_acc: 0.9298 | test_loss: 0.0934 | test_acc: 0.9502\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03a2651f3f7c40a9872f8ab73273743a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | train_loss: 0.0825 | train_acc: 0.9543 | test_loss: 0.0802 | test_acc: 0.9539\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afb32b7ba4524ec6aa2561287e269383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set random seeds\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "# Set number of epochs\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "# Start the timer\n",
    "from timeit import default_timer as timer\n",
    "start_time = timer()\n",
    "\n",
    "# Train model\n",
    "model_0_results = train(model=model_0,\n",
    "                        train_dataloader=train_dataloader,\n",
    "                        test_dataloader=test_dataloader,\n",
    "                        optimizer=optimizer,\n",
    "                        loss_fn=loss_fn,\n",
    "                        epochs=NUM_EPOCHS)\n",
    "\n",
    "# End the timer and print out how long it took\n",
    "end_time = timer()\n",
    "print(f\"Total training time: {end_time-start_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UlVbrOIp6t6w"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "063479aeceae458e8382e5270c1368a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0e751d8cfa9b4b018f53154e79912c3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_42cbdbf178424a859cf8b017904ffb65",
      "max": 50000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d1e39dac365c4909b35a5cbbf99578cd",
      "value": 50000
     }
    },
    "11943b53b4724193a73924d3d692488e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1208b62ba06e4009a7e07cf4d6e0df3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_48294fc2a3e64382a3a5af7a37b69317",
      "placeholder": "​",
      "style": "IPY_MODEL_61384ea5ec6a47b9aebe1ae3f981b206",
      "value": "  0%"
     }
    },
    "3fb22ccf76bf4c0d83acc0c1c04987b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3fc1b5eba23d4fec824f4204270ab7df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7a932c7673be4f8d8e1c262c7f1045d9",
      "placeholder": "​",
      "style": "IPY_MODEL_443270b905554c14af2da66c14ca332a",
      "value": "Training: 100%"
     }
    },
    "42cbdbf178424a859cf8b017904ffb65": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "43c5458339d149f9accef7a6bf96c112": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "443270b905554c14af2da66c14ca332a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "48294fc2a3e64382a3a5af7a37b69317": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "48f38e504c9943d2ada8432fba672a5c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5cc6ced4a8884baf83e0f513a8320717": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3fc1b5eba23d4fec824f4204270ab7df",
       "IPY_MODEL_0e751d8cfa9b4b018f53154e79912c3b",
       "IPY_MODEL_c45e2aeb0f4049278b48877b7c7e4feb"
      ],
      "layout": "IPY_MODEL_11943b53b4724193a73924d3d692488e"
     }
    },
    "61384ea5ec6a47b9aebe1ae3f981b206": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7a932c7673be4f8d8e1c262c7f1045d9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aa1114ba88924695923a00706f2ddf67": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b0d7f26663d74cc9877924a1cfd337d3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bfdbd85bb84844fb8b4f39cce3cd7fb1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b0d7f26663d74cc9877924a1cfd337d3",
      "max": 5,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_43c5458339d149f9accef7a6bf96c112",
      "value": 0
     }
    },
    "c16517ff94954b74a9d9e683c89584aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_48f38e504c9943d2ada8432fba672a5c",
      "placeholder": "​",
      "style": "IPY_MODEL_063479aeceae458e8382e5270c1368a1",
      "value": " 0/5 [00:00&lt;?, ?it/s]"
     }
    },
    "c45e2aeb0f4049278b48877b7c7e4feb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aa1114ba88924695923a00706f2ddf67",
      "placeholder": "​",
      "style": "IPY_MODEL_3fb22ccf76bf4c0d83acc0c1c04987b8",
      "value": " 50000/50000 [27:53&lt;00:00, 38.11it/s, loss=4.41, accuracy=0.874]"
     }
    },
    "cbe6efd79de14fec8b3f6d1de6a88f66": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1e39dac365c4909b35a5cbbf99578cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d23fb7552f7042648c934374c8ed6b9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1208b62ba06e4009a7e07cf4d6e0df3f",
       "IPY_MODEL_bfdbd85bb84844fb8b4f39cce3cd7fb1",
       "IPY_MODEL_c16517ff94954b74a9d9e683c89584aa"
      ],
      "layout": "IPY_MODEL_cbe6efd79de14fec8b3f6d1de6a88f66"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
